{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e183950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary modules/libraries \n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5feb9792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'val']\n"
     ]
    }
   ],
   "source": [
    "dataDir = \"./data\"\n",
    "print(os.listdir(dataDir)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6aa0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diseased cotton leaf', 'diseased cotton plant', 'fresh cotton leaf', 'fresh cotton plant']\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(dataDir + \"/train\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3f64be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples for diseased cotton leaf class :  288\n",
      "['dis_leaf (1)_iaip.jpg', 'dis_leaf (10)_iaip.jpg', 'dis_leaf (101)_iaip.jpg', 'dis_leaf (102)_iaip.jpg', 'dis_leaf (103)_iaip.jpg']\n"
     ]
    }
   ],
   "source": [
    "diseasedCottonLeaf = os.listdir(dataDir + \"/train/diseased cotton leaf\")\n",
    "print(\"Number of training examples for diseased cotton leaf class : \", len(diseasedCottonLeaf))\n",
    "print(diseasedCottonLeaf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1ae64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples for diseased cotton leaf class : 288\n",
      "Number of training examples for diseased cotton plant class : 815\n",
      "Number of training examples for fresh cotton leaf class : 427\n",
      "Number of training examples for fresh cotton plant class : 421\n"
     ]
    }
   ],
   "source": [
    "for i in classes:\n",
    "    result = os.listdir(dataDir + \"/train/\" + i)\n",
    "    print(f\"Number of training examples for {i} class : {len(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e614925",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "batch_size = 128\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83496788",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ImageFolder(dataDir + \"/train\", transform = T.Compose([T.Resize(image_size), T.CenterCrop(image_size), T.ToTensor(), T.Normalize(*stats)]))\n",
    "val_df = ImageFolder(dataDir + \"/val\", transform = T.Compose([T.Resize(image_size), T.CenterCrop(image_size), T.ToTensor(), T.Normalize(*stats)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c56cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_df, batch_size, shuffle = True, num_workers = 3, pin_memory = True)\n",
    "val_dl = DataLoader(val_df, batch_size*2, num_workers = 4, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38845d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[0][0] + stats[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93c84ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = train_df[0]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8984a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nmax = 64):\n",
    "    fig, ax = plt.subplots(figsize = (8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow = 8).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dl, nmax=64):\n",
    "    for images, _ in dl:\n",
    "        show_images(images, nmax)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "show_batch(train_dl)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b08021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
